{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f82f2f69-45e4-4889-876b-39e50aecc35c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow databricks-openai databricks-agents\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b76810d-c9d8-4494-b434-b8b92cd31ab6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def nimble_health_providers(city: str, display: bool = False):\n",
    "    df = spark.sql(f\"SELECT * FROM `dais-hackathon-2025`.nimble.dbx_google_maps_search_daily where array_contains(business_category, 'Health')\")\n",
    "    pdf = df.toPandas()\n",
    "    pdf = pdf[pdf.city == city]\n",
    "    # stringify arrays and complex data\n",
    "    for col in pdf.columns:\n",
    "        if pdf[col].apply(lambda x: isinstance(x, (list, tuple, np.ndarray))).any():\n",
    "            pdf[col] = pdf[col].apply(str)\n",
    "    # display\n",
    "    if display:\n",
    "        df.show()\n",
    "    # return\n",
    "    return pdf\n",
    "\n",
    "# df = nimble_health_providers(city=\"Asheville\", display=False)\n",
    "# # print(df)\n",
    "# print(str(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec782f3d-ed5a-43c0-b083-6b046f8d45d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import json\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_openai import UCFunctionToolkit, DatabricksFunctionClient\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "MODEL_NAME = \"databricks-meta-llama-3-1-8b-instruct\"\n",
    "\n",
    "# Get an OpenAI client configured to connect to Databricks model serving endpoints\n",
    "# Use this client to query the LLM\n",
    "openai_client = WorkspaceClient().serving_endpoints.get_open_ai_client()\n",
    "\n",
    "# Enable automatic tracing for easier debugging\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# Load Databricks built-in tools (Python code interpreter)\n",
    "client = DatabricksFunctionClient()\n",
    "\n",
    "class ToolResult:\n",
    "  def __init__(self, value):\n",
    "    self.value = value\n",
    "\n",
    "tools = []\n",
    "\n",
    "# weather\n",
    "\n",
    "def get_weather(city: str) -> ToolResult:\n",
    "  if city == \"Tokyo\":\n",
    "    value = \"sunny\"\n",
    "  elif city == \"Paris\":\n",
    "    value = \"rainy\"\n",
    "  else:\n",
    "    value = \"unknown\"\n",
    "  return ToolResult(value)\n",
    "weather_tool = {\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"get_weather\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"city\": {\"type\": \"string\"}\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "tools.append(weather_tool)\n",
    "\n",
    "# health data\n",
    "# get pdf_markdown_str\n",
    "# df = nimble_health_providers(True)\n",
    "# pdf = df.toPandas()\n",
    "# for col in pdf.columns:\n",
    "#     if pdf[col].apply(lambda x: isinstance(x, (list, tuple, np.ndarray))).any():\n",
    "#         pdf[col] = pdf[col].apply(str)\n",
    "# pdf_markdown_str = pdf.to_markdown(index=False)\n",
    "#\n",
    "def get_health_provider_data(city: str) -> ToolResult:\n",
    "    pdf = nimble_health_providers(city, True)\n",
    "    for col in pdf.columns:\n",
    "        if pdf[col].apply(lambda x: isinstance(x, (list, tuple, np.ndarray))).any():\n",
    "            pdf[col] = pdf[col].apply(str)\n",
    "    pdf_markdown_str = pdf.to_markdown(index=False)\n",
    "    return ToolResult(pdf_markdown_str)\n",
    "#\n",
    "get_health_provider_data_tool = {\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"get_health_provider_data\",\n",
    "    \"parameters\": {\n",
    "      \"city\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The city for which to retrieve health provider data.\"\n",
    "      }\n",
    "    },\n",
    "  }\n",
    "}\n",
    "tools.append(get_health_provider_data_tool)\n",
    "\n",
    "\n",
    "def call_tool(tool_name, parameters):\n",
    "  if tool_name == \"get_weather\":\n",
    "    return get_weather(**parameters)\n",
    "  elif tool_name == \"get_health_provider_data\":\n",
    "    return get_health_provider_data(**parameters)\n",
    "  raise ValueError(f\"Unknown tool: {tool_name}\")\n",
    "\n",
    "# ...\n",
    "def addToolResultToPrompt(prompt, tool_name, tool_result_value):\n",
    "  return (\n",
    "    f\"{prompt}\\n\\n\"\n",
    "    f\"NOTE: The tool '{tool_name}' was run and returned the following result: {tool_result_value}\\n\"\n",
    "    \"Please use this result to answer the user's question.\"\n",
    "  )\n",
    "\n",
    "# ...\n",
    "def run_agent(prompt):\n",
    "  \"\"\"\n",
    "  Send a user prompt to the LLM and return a list of LLM response messages\n",
    "  The LLM is allowed to call the code interpreter tool, if needed, to respond to the user\n",
    "  \"\"\"\n",
    "\n",
    "  system_prompt = (\n",
    "    \"You are an assistant that can use external tools. \"\n",
    "    \"If a tool result is available, always use the tool result to answer the user's question. \"\n",
    "    \"If no tool result is available, proceed as usual.\"\n",
    "  )\n",
    "\n",
    "  toolResultPresent = False\n",
    "  while True:\n",
    "    result_msgs = []\n",
    "    msgs = [\n",
    "      {\"role\": \"system\", \"content\": system_prompt},\n",
    "      {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    # only use tools on the first call\n",
    "    if toolResultPresent:\n",
    "      insertTools = []\n",
    "    else:\n",
    "      insertTools = tools\n",
    "    # call\n",
    "    response = openai_client.chat.completions.create(\n",
    "      model=MODEL_NAME,\n",
    "      messages=msgs,\n",
    "      tools=insertTools,\n",
    "    )\n",
    "    \n",
    "    msg = response.choices[0].message\n",
    "    result_msgs.append(msg.to_dict())\n",
    "    # If the model executed a tool, get the result\n",
    "    if msg.tool_calls:\n",
    "      call = msg.tool_calls[0]\n",
    "      tool_result = call_tool(call.function.name, json.loads(call.function.arguments))\n",
    "      prompt = addToolResultToPrompt(prompt, call.function.name, tool_result.value)\n",
    "      toolResultPresent = True\n",
    "      continue\n",
    "    # return after getting a result from the LLM assistant\n",
    "    break\n",
    "  return result_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b076a21-a290-4643-a98b-cd131c7bf7d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# answer = run_agent(\"Tell me the weather in tokyo\")\n",
    "answer = run_agent(\"I need a provider in New York\")\n",
    "for message in answer:\n",
    "  print(f'{message[\"role\"]}: {message[\"content\"]}')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "zach - agent test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
